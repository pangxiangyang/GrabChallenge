{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grab_v3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S85sBJO83Gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Break dataset into multiple dataset per unique geohash\n",
        "def splitDataset(data):\n",
        "  dict_of_df = {}\n",
        "  alluniqueGeohash = data.geohash6.unique()\n",
        "  geospecificdata = pd.DataFrame();\n",
        "  for geohash in alluniqueGeohash:\n",
        "    keyName = geohash;\n",
        "    dict_of_df[keyName] = data.loc[data['geohash6'] == keyName]\n",
        "    print( keyName + \" dataset created\")\n",
        "  return dict_of_df, alluniqueGeohash;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WHHY1fV83Gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert day & timestamp into date\n",
        "def parseToDateTime( geospecificdata):\n",
        "\n",
        "  currentDate = date.today()\n",
        "  maxDay = max(geospecificdata['day']) + 1;\n",
        "\n",
        "  for index,row in geospecificdata.iterrows():    \n",
        "      historyStart = currentDate - timedelta(days= maxDay -row['day'])  \n",
        "      dateTime = datetime.datetime.strptime( str( historyStart) + row['timestamp'], \"%Y-%m-%d%H:%M\")\n",
        "      geospecificdata.at[index,'Datetime'] = dateTime;\n",
        "\n",
        "  newdf = geospecificdata.sort_values(by=[('Datetime' )], inplace = False ).copy()\n",
        "  return newdf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1FPFIKz83Gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split into train and test sets\n",
        "def splitTrainTest( data ):\n",
        "    \n",
        "  train_size = int(len(data) * trainRatio)\n",
        "  test_size = len(data) - train_size\n",
        "  trainData, testData = data[:train_size], data.tail(test_size)\n",
        "  \n",
        "  # Get the subset of the data for training\n",
        "  training_set = trainData.iloc[:, 3].values\n",
        "\n",
        "  # Create input for training\n",
        "  import numpy as np\n",
        "  X_train = []\n",
        "  y_train =[]\n",
        "  for i in range(nrofinputs, len(training_set)):\n",
        "      X_train.append(training_set[i-nrofinputs:i]);\n",
        "      y_train.append(training_set[i])\n",
        "\n",
        "  X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "  if(len(X_train) > 0 ):\n",
        "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "  return X_train,y_train,trainData,testData"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qycwLIA83Gs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot demand vs DateTime\n",
        "def plotData( geospecificdata):\n",
        "\n",
        "  plt.figure(figsize=(20,10))\n",
        "  plt.plot(geospecificdata['Datetime'], geospecificdata['demand'], linestyle = 'solid', marker = 'None')\n",
        "  plt.title( geospecificdata.iloc[0,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8azsUt583Gw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate( regressor, trainData, testData, isLSTM ):\n",
        "    training_set = trainData.iloc[:, 3].values\n",
        "    # Create test data for prediction\n",
        "    test_set = training_set[-nrofinputs:]\n",
        "    #test_set = np.concatenate(( test_set ,(testData.iloc[:, 3].values)) )\n",
        "\n",
        "    predictedValues = [];\n",
        "    results = [];\n",
        "    X_test = np.array(test_set[0:nrofinputs]  );\n",
        "    X_test = X_test.reshape(-1,nrofinputs)\n",
        "    predictedValues = regressor.predict(X_test)\n",
        "    results.append( predictedValues[0])\n",
        "    X_test = np.append( np.delete(X_test, 0 ), predictedValues[0] );\n",
        "\n",
        "    # Make prediction\n",
        "    for i in range(nrofinputs + 1, len(testData) + nrofinputs ):\n",
        "        if( isLSTM):\n",
        "            X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "        X_test = X_test.reshape(-1,nrofinputs)\n",
        "        predictedValues = regressor.predict(X_test);\n",
        "        results.append( predictedValues[0])\n",
        "        X_test = np.append( np.delete(X_test, 0 ), predictedValues[0] );\n",
        "    return results;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ObzvPij83Gz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compileAndVisualizeResult( data, predictedValues, isVisualize, name ):\n",
        "  \n",
        "  # Get actualValues\n",
        "  train_size = int(len(data) * trainRatio )\n",
        "  test_size = len(data) - train_size\n",
        "  actualValues = data['demand'].tail(test_size).values\n",
        "  # Calculate RMSE\n",
        "  rmse = sqrt(mean_squared_error(actualValues, predictedValues ))\n",
        "  print('Test RMSE: %.3f' % rmse)\n",
        "  \n",
        "  # Store result in dictionary\n",
        "  result = pd.DataFrame();\n",
        "  result[\"ActualValues\"] = actualValues;\n",
        "  result[\"PredictedValues\"] = predictedValues;\n",
        "  result['RMSE'] = rmse;\n",
        "  dict_of_results[name] = result;\n",
        " \n",
        "  # Visualising the results\n",
        "  if( isVisualize):\n",
        "      plt.plot(data['Datetime'].tail(test_size), actualValues, color = 'red', label = 'Actual demand')\n",
        "      plt.plot(data['Datetime'].tail(test_size), predictedValues, color = 'blue', label = 'Predicted demand')\n",
        "      plt.title('Actual vs predicted')\n",
        "      plt.xlabel('Datetime')\n",
        "      plt.ylabel('Demand')\n",
        "      plt.legend()\n",
        "      plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTT-qWpG83G2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def buildGradientBoostingRegressor( X_train, y_train ):\n",
        "    clf = GradientBoostingRegressor(n_estimators=200, max_depth=3, random_state=23)\n",
        "    lr_train = X_train.reshape(-1,nrofinputs)\n",
        "    clf.fit(lr_train, y_train)\n",
        "    return clf;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGOodoMc83G6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def buildRandomForestRegressor( X_train, y_train ):\n",
        "    # Initialize Random Forest Regressor from scikit-learn\n",
        "    clf = RandomForestRegressor(n_estimators=200, n_jobs=-1, random_state=23)\n",
        "    lr_train = X_train.reshape(-1,nrofinputs)\n",
        "    clf.fit(lr_train, y_train)\n",
        "    return clf;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDf-6Pyi83G9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def buildLinearRegressor( X_train, y_train):\n",
        "    #implement linear regression\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    model = LinearRegression()\n",
        "    lr_train = X_train.reshape(-1,nrofinputs)\n",
        "    model.fit(lr_train,y_train)\n",
        "    return model;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8hTStH583HD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def exportModel( model,name, isKeras, isLR, isGBR ):\n",
        "  if( isKeras):\n",
        "    name = MODEL_FILE_PATH + name + \".h5\"\n",
        "    model.save( name )\n",
        "  else:\n",
        "    if(isLR):\n",
        "      name = MODEL_FILE_PATH + name + \".sav\";\n",
        "    elif( isGBR ):\n",
        "      name = MODEL_FILE_PATH + name + \".sav\"\n",
        "    else:\n",
        "      name = MODEL_FILE_PATH + name + \".sav\"\n",
        "    joblib.dump( model, name );"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyZRPgCz83HH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get data for testing\n",
        "def processTestData( data, nrofinputs ):\n",
        "  # Get the subset of the data for testing\n",
        "  testing_set = data.iloc[:, 3].values\n",
        "  # Create input for testing\n",
        "  X_test = []\n",
        "  X_test.append(testing_set[len(testing_set)-nrofinputs:len(testing_set)]);\n",
        "\n",
        "  X_test = np.array(X_test)\n",
        "  if(len(X_test) > 0 ):\n",
        "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "  return X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyiEqAuf83HL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getNrofInputs(data):\n",
        "    nrofdata = len(data);\n",
        "    nrofdays = len(data.day.unique() )\n",
        "    averagedataperday = int( nrofdata / nrofdays );\n",
        "    nrOfInput = averagedataperday * 7;\n",
        "    return nrOfInput"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9CMt7xc83HO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict( testFilepath, modelFolderpath, isVisualizeResult ):\n",
        "    \n",
        "    dict_of_test_results = {};\n",
        "    # Test filepath\n",
        "    data = pd.read_csv( testFilepath );\n",
        "    \n",
        "    # Split test file into multiple dataset\n",
        "    dict_of_test_df, alluniqueTestGeohash = splitDataset(data);\n",
        "    count = 1;\n",
        "    \n",
        "    # Define number of predictions, default will be 5\n",
        "    nroftimesteppredicted = 5;\n",
        "    \n",
        "    with open('nrofinputs.pkl', 'rb') as f:\n",
        "        dict_of_nr_inputs = pickle.load(f)\n",
        "    \n",
        "    # Loop thorough all GeoHash\n",
        "    for geoHash in alluniqueTestGeohash:\n",
        "        print(\"Testing-----------------------------\", count, geoHash)\n",
        "        df = parseToDateTime( dict_of_test_df[geoHash] );\n",
        "        \n",
        "        nrofinputs = dict_of_nr_inputs[geoHash];\n",
        "        \n",
        "        # Get the number of inputs from history\n",
        "        X_test = processTestData( df, nrofinputs );\n",
        "        X_test_array = np.array(X_test).reshape(1,X_test.shape[1] )\n",
        "    \n",
        "        # Get the pre-trained model based on geohash code\n",
        "        filename = modelFolderpath + geoHash + \".sav\"\n",
        "        model = joblib.load(filename)\n",
        "        results = [];\n",
        "        \n",
        "        # Perform recurvie multi-step forecast\n",
        "        # 1st predicted value will be used as input to predict next value\n",
        "        for i in range( 0, nroftimesteppredicted ):\n",
        "            inputRow = np.array( X_test_array[0] )\n",
        "            inputRow = inputRow.reshape(1,inputRow.shape[0])\n",
        "            predictedValues = model.predict(inputRow )\n",
        "            results.append(predictedValues[0])\n",
        "            \n",
        "            # Discard first value from inputs, and append predicted value to the end of array\n",
        "            X_test_array = np.append( np.delete(X_test_array, 0 ), predictedValues[0] );\n",
        "            X_test_array = X_test_array.reshape(1,X_test.shape[1] )\n",
        "        \n",
        "        count = count + 1;\n",
        "        dict_of_test_results[geoHash] = results;\n",
        "        # Plot the results\n",
        "        if( isVisualizeResult ):\n",
        "          plt.figure(figsize=(20,10))\n",
        "          plt.plot(df.iloc[len(df) - len(results):len(df)]['Datetime'], results, linestyle = 'solid', marker = 'None')\n",
        "          plt.title( geoHash)\n",
        "    return dict_of_test_results;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig2PPgGP93C8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ImportData(filepath):\n",
        "  # Import data\n",
        "\n",
        "  #Mount google drive\n",
        "  #from google.colab import drive \n",
        "  #drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "  #Read the file from google drive\n",
        "  data = pd.read_csv( filepath )\n",
        "  #data = pd.read_csv( 'gdrive/My Drive/Machine Learning Playground/training.csv' )\n",
        "\n",
        "  # Split into multiple datasets based on Hash\n",
        "  dict_of_df, alluniqueGeohash = splitDataset(data);\n",
        "  return dict_of_df, alluniqueGeohash;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ql00g6fG83HY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Train( dict_of_df, alluniqueGeohash ):\n",
        "   \n",
        "  count = 1;\n",
        "  # LinearRegressor\n",
        "  for geoHash in alluniqueGeohash:\n",
        "      print(\"Linear Regression----------------------------\", count, geoHash)\n",
        "      \n",
        "      # Convert day & timestamp into datetime\n",
        "      df = parseToDateTime( dict_of_df[geoHash] );\n",
        "      \n",
        "      # Calculate number of inputs per geohash\n",
        "      nrofinputs = getNrofInputs(dict_of_df[geoHash] );\n",
        "      dict_of_nrofinputs[geoHash] = nrofinputs\n",
        "      \n",
        "      # Visualize the results, can be disabled to speed up the training\n",
        "      if( isVisualizeResult):\n",
        "        plotData(df); \n",
        "      \n",
        "      # Split the dataset into train - test \n",
        "      X_train, y_train, trainData, testData = splitTrainTest(df);\n",
        "      \n",
        "      \n",
        "      if(len(X_train) > 0 and len(y_train ) > 0):\n",
        "        \n",
        "        # Build Linear regression model\n",
        "        dict_of_model_lr[geoHash] = buildLinearRegressor( X_train, y_train)\n",
        "        \n",
        "        # Validate the results\n",
        "        predictedValues_lr = validate( dict_of_model_lr[geoHash], trainData, testData, isKeras )\n",
        "        \n",
        "        # Compute results in RMSE and visualize the results\n",
        "        compileAndVisualizeResult( df, predictedValues_lr, isVisualizeResult, geoHash )\n",
        "        \n",
        "        # export models to local filepath\n",
        "        exportModel( dict_of_model_lr[geoHash], geoHash, isKeras, isLR, isGBR )\n",
        "      count = count + 1;\n",
        "\n",
        "  # Export expected number of inputs\n",
        "  f = open(\"nrofinputs.pkl\",\"wb\")\n",
        "  pickle.dump(dict_of_nrofinputs,f)\n",
        "  f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua29OE9c_D1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Main execution block\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime \n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.externals import joblib\n",
        "from math import sqrt\n",
        "from datetime import date, timedelta\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "# Define variable\n",
        "TRAINING_FILE_PATH = 'C:/Users/PXY/Desktop/training.csv';\n",
        "TESTING_FILE_PATH = 'C:/Users/PXY/Desktop/training.csv';\n",
        "MODEL_FILE_PATH = \"C:/Users/PXY/Desktop/Models_LR/\";\n",
        "trainRatio = 0.8\n",
        "nrofinputs = 50\n",
        "dict_of_model_arima = {};\n",
        "dict_of_model_lr = {};\n",
        "dict_of_model_gbr = {};\n",
        "dict_of_model_rfr = {};\n",
        "dict_of_model_lstm = {};\n",
        "dict_of_results = {};\n",
        "dict_of_nrofinputs = {};\n",
        "dict_of_predicted_results = {};\n",
        "\n",
        "isKeras = False;\n",
        "isLSTM = False;\n",
        "isLR = True;\n",
        "isGBR = False;\n",
        "isVisualizeResult = False;\n",
        "\n",
        "dict_of_df, alluniqueGeohash = ImportData( TRAINING_FILE_PATH );\n",
        "Train(dict_of_df, alluniqueGeohash)\n",
        "dict_of_predicted_results = predict( TESTING_FILE_PATH, MODEL_FILE_PATH, isVisualizeResult)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsXvXwb-GmP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_of_predicted_results = predict( TESTING_FILE_PATH, MODEL_FILE_PATH, False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}